{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840c286f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install awscli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a1d00f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!aws configure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84b6a9",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!aws s3 ls s3://spacenet-dataset/AOIs/AOI_1_Rio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f6974",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir datasets/AOIs/AOI_1_Rio && aws s3 cp s3://spacenet-dataset/AOIs/AOI_1_Rio/processedData/processedBuildingLabels.tar.gz datasets/AOIs/AOI_1_Rio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b519d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Unzip the main folder\n",
    "!tar -xvzf datasets/AOIs/AOI_1_Rio/processedBuildingLabels.tar.gz -C datasets/AOIs/AOI_1_Rio/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bc6d5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Unzip 3band satellite images\n",
    "!tar -xvzf datasets/AOIs/AOI_1_Rio/processedBuildingLabels/3band.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4ba3f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Unzip geojson containing labels satellite images\n",
    "!tar -xvzf datasets/AOIs/AOI_1_Rio/processedBuildingLabels/vectordata/geojson.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e055928d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6ee5eb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "images_folder = \"3band\"\n",
    "labels_folder = \"geojson\"\n",
    "print(len([name for name in os.listdir(images_folder)]), \"satellite images\")\n",
    "print(len([name for name in os.listdir(labels_folder)]), \"geojson labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61310dcc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28ac321",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69edd509",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Define transformers\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(448, 448),  # Make divisible by 32 (2^5)\n",
    "    A.HorizontalFlip(),\n",
    "    A.VerticalFlip(),\n",
    "    A.RandomRotate90(),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(448, 448),\n",
    "    A.Normalize(),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b301168",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "from RioDataset import RioDataset\n",
    "train_dataset = RioDataset(\n",
    "    tiff_dir=images_folder,\n",
    "    geojson_dir=labels_folder,\n",
    "    transform=train_transform\n",
    ")\n",
    "\n",
    "val_dataset = RioDataset(\n",
    "    tiff_dir=images_folder,\n",
    "    geojson_dir=labels_folder,\n",
    "    transform=val_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1a2af0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "num_workers = 2\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=False, num_workers=num_workers)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0712fac",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "from models.unet.model import UNet\n",
    "model = UNet(num_classes=1, in_channels=3)  # Adjust in_channels based on your .tiff files\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device: \", device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd2e8c6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from DiceBCELoss import DiceBCELoss\n",
    "criterion = DiceBCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3345d8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Trainig Loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    \n",
    "    for images, masks in train_loader:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    dice_score = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "            # Calculate Dice coefficient\n",
    "            pred = torch.sigmoid(outputs) > 0.5\n",
    "            dice_score += (2 * (pred * masks).sum()) / ((pred + masks).sum() + 1e-8)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, '\n",
    "          f'Val Loss: {val_loss/len(val_loader):.4f}, Dice: {dice_score/len(val_loader):.4f}')\n",
    "    \n",
    "    # Update learning rate based on validation loss\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'building_segmentation_model.pth')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
